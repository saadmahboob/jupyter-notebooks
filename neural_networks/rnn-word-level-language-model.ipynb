{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Token Prediction\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Data Cleaning and Preprocessing](#data-clean)\n",
    "    * [Bias and Noise](#data-bias)\n",
    "    * [Lemmatization](#data-lemma)\n",
    "    * [Encoding](#data-encoding)\n",
    "    * [Sequences](#model-sequences)\n",
    "* [Model](#model) \n",
    "    * [Architecture](#model-selection)\n",
    "    * [Loss Function](#model-loss)\n",
    "* [Future Work](#future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import nltk\n",
    "# Uncomment to download stopwords\n",
    "# nltk.download('stopwords')\n",
    "# Uncomment to download Lemmatizer related package\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# Uncomment to download wordnet\n",
    "# nltk.download('wordnet')\n",
    "import pickle\n",
    "import matplotlib as mt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "# Interactive Tools for Matplotlib\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# map words to integers\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"data-clean\"></a>Data Cleaning and Preprocessing\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-saved and pre-trained models and data set.\n",
    "# If using these, skip to the section on `Prediction`.\n",
    "\n",
    "# Uncomment to load small sequence data. You can then skip to `Model` section.\n",
    "sequences = np.load('data/seqs/seq.np.npy')\n",
    "\n",
    "# Uncomment to load the preprocessed data set\n",
    "# df = pd.read_csv('data/processed.csv')\n",
    "\n",
    "# Uncomment to load the label encoder\n",
    "with open('models/tokenizer.p', 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "# Uncomment to load the language model\n",
    "# with open('models/language.p', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set. Consider lazy loading \n",
    "# due to the large file size\n",
    "df = pd.read_csv('data/search_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103913566 entries, 0 to 103913565\n",
      "Data columns (total 3 columns):\n",
      "key       object\n",
      "time      int64\n",
      "userId    int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"data-bias\"></a>Bias and Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data rows with undefined keys.\n",
    "# Note: As an alternative to dropping rows with undefined keys,\n",
    "#       we could try to impute the undefined values by sampling \n",
    "#       from the conditional (on userId) distribution of keys.\n",
    "df = df.dropna(subset=['key'])\n",
    "# In a general corpus of text, stopwords dominate\n",
    "# histogram counts, causing biased word frequency counts. \n",
    "# For this reason, we remove stopwords from language models.\n",
    "df = df[~df['key'].isin(stopwords.words('english'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key       False\n",
       "time      False\n",
       "userId    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb857b64898>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb8580b21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, figsize=(16, 5))\n",
    "\n",
    "# Check for selection bias\n",
    "df['userId'].plot(kind='hist', ax=ax, title='Member Activity Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is a clear bias towards one of the early members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove search tokens of outlier users\n",
    "counts = df.groupby(df.userId).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19542524</td>\n",
       "      <td>19542524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672434</th>\n",
       "      <td>29163</td>\n",
       "      <td>29163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198364</th>\n",
       "      <td>16264</td>\n",
       "      <td>16264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655782</th>\n",
       "      <td>15806</td>\n",
       "      <td>15806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890254</th>\n",
       "      <td>15182</td>\n",
       "      <td>15182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              key      time\n",
       "userId                     \n",
       "1        19542524  19542524\n",
       "1672434     29163     29163\n",
       "198364      16264     16264\n",
       "3655782     15806     15806\n",
       "2890254     15182     15182"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = counts.sort_values(by='key', ascending=False)\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User with id 1 has orders of magnitude more search queries than anyone else. This user is likely an automated system\n",
    "or a team of iternal developers running tests. We remove this row from the data set to avoid this bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.userId != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"data-lemma\"></a>Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing words bring them to a canonical form by factoring out the stem, \n",
    "# converting pos types (noun, verb, etc..) to a specified pos tag, as well \n",
    "# as lowering the cases.\n",
    "wnl = WordNetLemmatizer()\n",
    "pos_translate = {'J':'a', 'V':'v', 'N':'n', 'R':'r'}\n",
    "fn = lambda key: wnl.lemmatize(key, pos='n')\n",
    "df['key'] = df['key'].apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>time</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43794838</th>\n",
       "      <td>wings free</td>\n",
       "      <td>17406560</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794839</th>\n",
       "      <td>wing</td>\n",
       "      <td>17406617</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794840</th>\n",
       "      <td>wings free</td>\n",
       "      <td>17406984</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794841</th>\n",
       "      <td>butterfly wings</td>\n",
       "      <td>17407482</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794842</th>\n",
       "      <td>butterfly wings</td>\n",
       "      <td>17407556</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794843</th>\n",
       "      <td>wing</td>\n",
       "      <td>17409994</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794844</th>\n",
       "      <td>fairy wings</td>\n",
       "      <td>17410392</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794845</th>\n",
       "      <td>fairy wings</td>\n",
       "      <td>17437090</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794846</th>\n",
       "      <td>mermaid</td>\n",
       "      <td>17437185</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794847</th>\n",
       "      <td>mermaid</td>\n",
       "      <td>17437381</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      key      time   userId\n",
       "43794838       wings free  17406560  2000000\n",
       "43794839             wing  17406617  2000000\n",
       "43794840       wings free  17406984  2000000\n",
       "43794841  butterfly wings  17407482  2000000\n",
       "43794842  butterfly wings  17407556  2000000\n",
       "43794843             wing  17409994  2000000\n",
       "43794844      fairy wings  17410392  2000000\n",
       "43794845      fairy wings  17437090  2000000\n",
       "43794846          mermaid  17437185  2000000\n",
       "43794847          mermaid  17437381  2000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['userId'] == int(2e6)].sort_values(by='time').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"data-encoding\"></a>Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>time</th>\n",
       "      <th>userId</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19563559</th>\n",
       "      <td>heart</td>\n",
       "      <td>41369281</td>\n",
       "      <td>2</td>\n",
       "      <td>969498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563560</th>\n",
       "      <td>heart</td>\n",
       "      <td>41369388</td>\n",
       "      <td>2</td>\n",
       "      <td>969498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563561</th>\n",
       "      <td>heart</td>\n",
       "      <td>41369687</td>\n",
       "      <td>2</td>\n",
       "      <td>969498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563562</th>\n",
       "      <td>heart</td>\n",
       "      <td>41369765</td>\n",
       "      <td>2</td>\n",
       "      <td>969498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563563</th>\n",
       "      <td>heart</td>\n",
       "      <td>41369822</td>\n",
       "      <td>2</td>\n",
       "      <td>969498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key      time  userId  embedding\n",
       "19563559  heart  41369281       2     969498\n",
       "19563560  heart  41369388       2     969498\n",
       "19563561  heart  41369687       2     969498\n",
       "19563562  heart  41369765       2     969498\n",
       "19563563  heart  41369822       2     969498"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a mapping from word to integer\n",
    "# e.g. f('hello') -> 1\n",
    "le = LabelEncoder()\n",
    "df['embedding'] = le.fit_transform(df['key'])\n",
    "# Uncomment to save the tokenizer\n",
    "# with open('models/tokenizer.p', 'wb') as f:\n",
    "#     pickle.dump(le, f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 84260377 entries, 19563559 to 103913565\n",
      "Data columns (total 3 columns):\n",
      "time         int64\n",
      "userId       int64\n",
      "embedding    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Having a trained encoder for words,\n",
    "# we can safely delete the `key` column from the data set.\n",
    "if 'key' in df.columns:\n",
    "    df = df.drop('key', axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save the preprocessed data set.\n",
    "# df.to_csv('data/processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"model-sequences\"></a>Sequences\n",
    "\n",
    "A key design decision is how long the input sequences should be. They need to be long enough to allow the model to learn the context for the words to predict. We will use sequences of length 50.\n",
    "\n",
    "**Note: The number of generated sequences will be very large, and a much better idea is to store it using the [HDF5](https://support.hdfgroup.org/HDF5/) format. For the sake of this example, we sample user data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequences length \n",
    "seq_length = 50\n",
    "# number of sampled users\n",
    "N = 100\n",
    "idx = np.random.choice(np.arange(df['userId'].median(),df['userId'].max()), size=N, replace=False)\n",
    "idx = idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 1270\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "# sample users\n",
    "tokens = df[df['userId'].isin(idx)]\n",
    "\n",
    "tokens = tokens.sort_values(by='time')\n",
    "groups = tokens.groupby('userId')\n",
    "\n",
    "for id, group in groups:\n",
    "    # organize into sequences of tokens\n",
    "    for i in range(seq_length+1, len(group)):\n",
    "        # select sequence of tokens\n",
    "        seq = group['embedding'].iloc[i-seq_length:i].values\n",
    "        # store\n",
    "        sequences.append(seq)\n",
    "\n",
    "# Uncomment to save the sequences\n",
    "# np.save('data/seqs/seq.np', sequences)      \n",
    "\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"model\"></a>Model\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"model-selection\"></a>Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a sequence to word model that learns a conditional distribution\n",
    "of a word given a sequence of previous words.\n",
    "\n",
    "$$P(w_{N}\\mid w_{N-1}, w_{N-2}, ..., w_{N-m}) = f(w_{N-1}, w_{N-2}, ..., w_{N-m})$$\n",
    "\n",
    "The predicted word will be fed in as input to in turn generate the next word.\n",
    "\n",
    "The model we will train is a neural language model. It has a few unique characteristics:\n",
    "\n",
    "* It uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n",
    "* It learns the representation at the same time as learning the model.\n",
    "* It learns to predict the probability for the next word using a context of previous words.\n",
    "* Specifically, we will use an Embedding Layer to learn the representation of words, and a Long Short-Term Memory (LSTM) recurrent neural network to learn to predict words based on their context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 49, 50)            118679850 \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 49, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2373596)           239733196 \n",
      "=================================================================\n",
      "Total params: 358,553,846\n",
      "Trainable params: 358,553,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(embedding_shape,\n",
    "              Cell=GRU, \n",
    "              Layers=1,\n",
    "              Dropout=0.,\n",
    "              Hidden=25,\n",
    "              outdim=1,\n",
    "              activation=\"softmax\"):\n",
    "    \"\"\"\n",
    "    Constructor for a multilayer recurrent network.\n",
    "    \n",
    "    :params embedding_shape tuple: (vocab_size, out_dim, seq_length)\n",
    "    :params Cell str: Type of cell unit used in the model (gru, lstm...)\n",
    "    :params Layers int: The number of hidden recurrent layers\n",
    "    :params Dropout float: Probability of Dropout [0; 1]\n",
    "    :params outdim int: dimension of output data. Default (1) regresses to \n",
    "                        a single value.\n",
    "    :param activation str: final activation layer type (e.g. \"linear\")\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Start with an embedding layer to convert sparse word vectors to dense ones.\n",
    "    vocab_size, out_dim, seq_length = embedding_shape\n",
    "    model.add(Embedding(vocab_size, out_dim, input_length=seq_length))\n",
    "    \n",
    "    # If the model has more than one recurrent layer,\n",
    "    # output all the sequences (not just the final one).\n",
    "    if Layers > 1:\n",
    "        return_sequences = True\n",
    "    else:\n",
    "        return_sequences = False\n",
    "        \n",
    "    # The first layer requires `input_shape` to be specified.\n",
    "    model.add(Cell(Hidden, \n",
    "                   return_sequences=return_sequences,\n",
    "                   # input_shape=input_shape,\n",
    "                   dropout=Dropout,\n",
    "                   recurrent_dropout=Dropout))\n",
    "\n",
    "    # Input shapes are inferred in the subsequent layers\n",
    "    for layer in range(Layers - 1):\n",
    "        # Make sure the final hidden layer does not output all the sequences.\n",
    "        if layer == Layers - 2:\n",
    "            return_sequences = False\n",
    "        model.add(Cell(Hidden,\n",
    "                       return_sequences=return_sequences, \n",
    "                       dropout=Dropout,\n",
    "                       recurrent_dropout=Dropout))\n",
    "    \n",
    "    # Add a final dense layer\n",
    "    model.add(Dense(outdim, activation=activation))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "embedding_shape = (len(le.classes_)+1, 50, seq_length)\n",
    "model = build_rnn(\n",
    "    embedding_shape=embedding_shape,\n",
    "    Cell=LSTM,\n",
    "    Layers=2,\n",
    "    # Ensure that model has enough capacity first\n",
    "    Dropout=0.,\n",
    "    Hidden=100,\n",
    "    outdim=len(le.classes_)\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = keras.utils.to_categorical(y, num_classes=len(le.classes_))\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"model-loss\"></a>Loss Function (example run)\n",
    "\n",
    "Since the model learns a conditional probability distribution, we will **categorical cross-entropy** as the measure of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1270/1270 [==============================] - 570s 449ms/step - loss: 14.6719 - acc: 0.0890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x8102e6c6a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    # Use tensorflow optimizers to avoid the conversion from sparse\n",
    "    # gradients to dense gradients due the Embedding layer. This can\n",
    "    # have a devastating effect on performance.\n",
    "    optimizer=tf.train.AdamOptimizer(), metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"future\"></a>Future Work\n",
    "---------------\n",
    "\n",
    "* Split the `keys` with more than one word into separate entries.\n",
    "* Experiment with more (fewer) number of recurrent layers.\n",
    "* Experiment with type of recurrent layers (GRU, etc...).\n",
    "* Use sklearn's `GridSearchCV` to tune hyperparameters (learning rate, etc...).\n",
    "* Use sklearn's `TimeSeriesSplit` to cross validate the time series data.\n",
    "* Run a full training session (with all the sequneces) on a GPU powered Amazon EC2 cluster.\n",
    "* Compare the performance of the recurrent neural network to an ARIMA model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
